{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Data&Augmentation Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqmrqYBhV9M1NJTBbEknNH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serereuk-tf/Tensorflow-Example/blob/main/Day1/TF_Data%26Augmentation_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyOa0K3xuyu8"
      },
      "source": [
        "# Day1 TF Data 설명 및 Augmentation 적용하는 방법\n",
        "이전에 사용했던 예제를 다시 올려두고 시작합시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahczR9OCuHNg"
      },
      "source": [
        "#unzip the Files\n",
        "!unzip -qq /content/train_tfrecord.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Womevtsvx4"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Tensorflow에서 알아서 최적화를 해주는 좋은 기능 #\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "CLASSES = 100\n",
        "IMAGE_SHAPE = [32, 32]\n",
        "AUG_BATCH = 128"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2cWToW1zGNm"
      },
      "source": [
        "def _onehot(image, label):\n",
        "    \"\"\"\n",
        "    Label를 One-hot으로 만들어주는 방법 - CutMix, Mixup 등에 사용\n",
        "    \"\"\"\n",
        "    return image, tf.one_hot(label, CLASSES)\n",
        "\n",
        "\n",
        "def _parse_function(serialized_item):\n",
        "    \"\"\"\n",
        "    TF Records에 있는 내용물들을 압축해제 하는 방법\n",
        "    이미지가 String으로 나오기 때문에 추가적으로 더 작업을 해줘야한다.\n",
        "    tf.io.decode_png를 통해서 Stinrg -> Image Array\n",
        "    Output:\n",
        "        * Image : Tensor\n",
        "        * Label : Tensor\n",
        "    \"\"\"\n",
        "    parsed_ = tf.io.parse_example(\n",
        "        serialized=serialized_item,\n",
        "        features={\n",
        "            \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\n",
        "            \"label\": tf.io.FixedLenFeature([], dtype=tf.int64)\n",
        "        }\n",
        "    )\n",
        "    image = parsed_['image']\n",
        "    image = tf.io.decode_png(image, channels=3)\n",
        "    # 아래 코드는 이미지를 [0, 1]로 만들어주는 역할\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    label = tf.cast(parsed_['label'], tf.int32)\n",
        "    return image, label"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb-W-M3kHqgV"
      },
      "source": [
        "# TF Data 톺아보기\n",
        "* batch\n",
        "* zip\n",
        "* prefetch\n",
        "* cache\n",
        "* interleave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_0oM5iZIMGV"
      },
      "source": [
        "## 1. batch\n",
        "\n",
        "*   주어진 Dataset을 batch_size만큼 나눠주는 역할을 하는 친구\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydy9IxuZI1lH"
      },
      "source": [
        "# Example\n",
        "a = tf.arange(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayo72qAJI_QE"
      },
      "source": [
        "## 2. zip \n",
        "\n",
        "* Python의 zip과 같은 역할을 함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJiFQPfUIIdC"
      },
      "source": [
        "train_dataset = tf.data.TFRecordDataset(\n",
        "    glob.glob('tfrecord_cifar100/train/tfr_*'))\n",
        "# Parsing\n",
        "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6SjVvkCHW7H"
      },
      "source": [
        "# Efficient Data Configuration\n",
        "#https://www.kaggle.com/harveenchadha/effnetb4-tf-data-gpu-aug-5x-speedup-tta\n",
        "\n",
        "def batch(ds, batch_size=64):\n",
        "    ds = ds.cache('./dump.tfcache')\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrCOLIg4cAxJ"
      },
      "source": [
        "# Image Augmentation을 적용하는 방법은 크게 3 가지\n",
        "\n",
        "1. tf dataset에서 tf.image를 사용하여 변경하는 방법\n",
        "    * 장점: Custom Augmentation을 적용하기 쉬움 함수로 만든 다음 map으로 씌우면 됨\n",
        "    * 단점: 잘못 짜면 약간 Idle이 생길수도 있음. \n",
        "2. tf.keras.layers를 활용하는 방법\n",
        "    * 장점: Sequential에 들어가기 때문에 굳이 Dataset을 수정 안해도 됨 모델 구조랑 연동 바로 가능, 가독성이 높음\n",
        "    * 단점: Custom하게 만들기가 약간 어려움\n",
        "3. ~~tf.Transform을 사용하는 방법~~ -> 새로운 Package로 이전함 TFX 참고\n",
        "    * 장점: 실제로 모델을 서빙할 때 편리하다고 함\n",
        "    * 단점: preprocessing_fn함수로 짜야하는데 예제가 별로 없음 ㅠㅠ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PApB9I6Vb_3U"
      },
      "source": [
        "# 1. Dataset을 활용한 방법\n",
        "\n",
        "def Augmentation(image):\n",
        "    \"\"\"\n",
        "    랜덤 Flip_LR를 적용한 모습 \n",
        "    Output:\n",
        "        * Image : Flipped Image\n",
        "    \"\"\"\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "# 2. tf.keras.layer를 활용하는 방법\n",
        "\n",
        "Augmentation2 = tf.keras.Sequential(\n",
        "    [tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal')])\n",
        "\n",
        "# 3. Transform을 사용하는 방법\n",
        "# import tfx\n",
        "# preprocessing_fn 이라는 함수만 정의하면 됨\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKvcA2WihN23"
      },
      "source": [
        "# Custom한 Augmentation 만들기 - CutMix Example\n",
        "출처 : https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTnq9bmvhNg3"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    DIM = IMAGE_SIZE[0]\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
        "        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
        "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n",
        "        imgs.append(img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,DIM,DIM,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6TrCzRvH74h"
      },
      "source": [
        "# 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5ciPL79zLRv"
      },
      "source": [
        "# TF Record 읽기\n",
        "train_dataset = tf.data.TFRecordDataset(\n",
        "    glob.glob('tfrecord_cifar100/train/tfr_*'))\n",
        "# Parsing\n",
        "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
        "train_dataset = train_dataset.map(Augmentation, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}